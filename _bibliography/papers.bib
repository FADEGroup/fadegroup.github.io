---
---

@string{aps = {American Physical Society,}}

@book{einstein1920relativity,
  title={Relativity: the Special and General Theory},
  author={Einstein, Albert},
  year={1920},
  publisher={Methuen & Co Ltd},
  html={relativity.html}
}

@book{einstein1956investigations,
  bibtex_show={true},
  title={Investigations on the Theory of the Brownian Movement},
  author={Einstein, Albert},
  year={1956},
  publisher={Courier Corporation},
  preview={brownian-motion.gif}
}

@article{einstein1950meaning,
  abbr={AJP},
  bibtex_show={true},
  title={The meaning of relativity},
  author={Einstein, Albert and Taub, AH},
  journal={American Journal of Physics},
  volume={18},
  number={6},
  pages={403--404},
  year={1950},
  publisher={American Association of Physics Teachers}
}

@article{PhysRev.47.777,
  abbr={PhysRev},
  title={Can Quantum-Mechanical Description of Physical Reality Be Considered Complete?},
  author={Einstein*†, A. and Podolsky*, B. and Rosen*, N.},
  abstract={In a complete theory there is an element corresponding to each element of reality. A sufficient condition for the reality of a physical quantity is the possibility of predicting it with certainty, without disturbing the system. In quantum mechanics in the case of two physical quantities described by non-commuting operators, the knowledge of one precludes the knowledge of the other. Then either (1) the description of reality given by the wave function in quantum mechanics is not complete or (2) these two quantities cannot have simultaneous reality. Consideration of the problem of making predictions concerning a system on the basis of measurements made on another system that had previously interacted with it leads to the result that if (1) is false then (2) is also false. One is thus led to conclude that the description of reality as given by a wave function is not complete.},
  journal={Phys. Rev.},
  location={New Jersey},
  volume={47},
  issue={10},
  pages={777--780},
  numpages={0},
  year={1935},
  month={May},
  publisher=aps,
  doi={10.1103/PhysRev.47.777},
  url={http://link.aps.org/doi/10.1103/PhysRev.47.777},
  html={https://journals.aps.org/pr/abstract/10.1103/PhysRev.47.777},
  pdf={example_pdf.pdf},
  altmetric={248277},
  dimensions={true},
  google_scholar_id={qyhmnyLat1gC},
  video={https://www.youtube-nocookie.com/embed/aqz-KE-bpKQ},
  additional_info={. *More Information* can be [found here](https://github.com/alshedivat/al-folio/)},
  annotation={* Example use of superscripts<br>† Albert Einstein},
  selected={true},
  inspirehep_id = {3255}
}

@article{einstein1905molekularkinetischen,
  title={{\"U}ber die von der molekularkinetischen Theorie der W{\"a}rme geforderte Bewegung von in ruhenden Fl{\"u}ssigkeiten suspendierten Teilchen},
  author={Einstein, A.},
  journal={Annalen der physik},
  volume={322},
  number={8},
  pages={549--560},
  year={1905},
  publisher={Wiley Online Library}
}

@article{einstein1905movement,
  abbr={Ann. Phys.},
  title={Un the movement of small particles suspended in statiunary liquids required by the molecular-kinetic theory 0f heat},
  author={Einstein, A.},
  journal={Ann. Phys.},
  volume={17},
  pages={549--560},
  year={1905}
}

@article{einstein1905electrodynamics,
  title={On the electrodynamics of moving bodies},
  author={Einstein, A.},
  year={1905}
}

@Article{einstein1905photoelectriceffect,
  bibtex_show={true},
  abbr={Ann. Phys.},
  title="{{\"U}ber einen die Erzeugung und Verwandlung des Lichtes betreffenden heuristischen Gesichtspunkt}",
  author={Albert Einstein},
  abstract={This is the abstract text.},
  journal={Ann. Phys.},
  volume={322},
  number={6},
  pages={132--148},
  year={1905},
  doi={10.1002/andp.19053220607},
  award={Albert Einstein receveid the **Nobel Prize in Physics** 1921 *for his services to Theoretical Physics, and especially for his discovery of the law of the photoelectric effect*},
  award_name={Nobel Prize}
}

@book{przibram1967letters,
  bibtex_show={true},
  title={Letters on wave mechanics},
  author={Einstein, Albert and Schrödinger, Erwin and Planck, Max and Lorentz, Hendrik Antoon and Przibram, Karl},
  year={1967},
  publisher={Vision},
  preview={wave-mechanics.gif},
  abbr={Vision}
}

{'title': 'Few-Shot Lifelong Learning', 'pub_year': 2021, 'citation': 'AAAI 2021, 2021', 'author': 'Pratik Mazumder* and Pravendra Singh* and Piyush Rai', 'journal': 'AAAI 2021', 'abstract': 'Many real-world classification problems often have classes with very few labeled training samples. Moreover, all possible classes may not be initially available for training, and may be given incrementally. Deep learning models need to deal with this two-fold problem in order to perform well in real-life situations. In this paper, we propose a novel Few-Shot Lifelong Learning (FSLL) method that enables deep learning models to perform lifelong/continual learning on few-shot data. Our method selects very few parameters from the model for training every new set of classes instead of training the full model. This helps in preventing overfitting. We choose the few parameters from the model in such a way that only the currently unimportant parameters get selected. By keeping the important parameters in the model intact, our approach minimizes catastrophic forgetting. Furthermore, we minimize the cosine similarity between the new and the old class prototypes in order to maximize their separation, thereby improving the classification performance. We also show that integrating our method with self-supervision improves the model performance significantly. We experimentally show that our method significantly outperforms existing methods on the miniImageNet, CIFAR-100, and CUB-200 datasets. Specifically, we outperform the state-of-the-art method by an absolute margin of 19.27% for the CUB dataset.'}
{'title': 'Calibrating CNNs for Lifelong Learning', 'pub_year': 2020, 'citation': 'Advances in Neural Information Processing Systems 33, 2020', 'author': 'Pravendra Singh* and Vinay Kumar Verma* and Pratik Mazumder and Lawrence Carin and Piyush Rai', 'journal': 'Advances in Neural Information Processing Systems', 'volume': '33', 'abstract': 'We present an approach for lifelong/continual learning of convolutional neural networks (CNN) that does not suffer from the problem of catastrophic forgetting when moving from one task to the other. We show that the activation maps generated by the CNN trained on the old task can be calibrated using very few calibration parameters, to become relevant to the new task. Based on this, we calibrate the activation maps produced by each network layer using spatial and channel-wise calibration modules and train only these calibration parameters for each new task in order to perform lifelong learning. Our calibration modules introduce significantly less computation and parameters as compared to the approaches that dynamically expand the network. Our approach is immune to catastrophic forgetting since we store the task-adaptive calibration parameters, which contain all the task-specific knowledge and is exclusive to each task. Further, our approach does not require storing data samples from the old tasks, which is done by many replay based methods. We perform extensive experiments on multiple benchmark datasets (SVHN, CIFAR, ImageNet, and MS-Celeb), all of which show substantial improvements over state-of-the-art methods (eg, a 29% absolute increase in accuracy on CIFAR-100 with 10 classes at a time). On large-scale datasets, our approach yields 23.8% and 9.7% absolute increase in accuracy on ImageNet-100 and MS-Celeb-10K datasets, respectively, by employing very few (0.51% and 0.35% of model parameters) task-adaptive calibration parameters.'}
{'title': 'Rectification-based Knowledge Retention for Continual Learning', 'pub_year': 2021, 'citation': 'IEEE Conference on Computer Vision and Pattern Recognition (CVPR) 2021, 2021', 'author': 'Pravendra Singh* and Pratik Mazumder* and Piyush Rai and Vinay P Namboodiri', 'conference': 'IEEE Conference on Computer Vision and Pattern Recognition (CVPR) 2021', 'abstract': 'Deep learning models suffer from catastrophic forgetting when trained in an incremental learning setting. In this work, we propose a novel approach to address the task incremental learning problem, which involves training a model on new tasks that arrive in an incremental manner. The task incremental learning problem becomes even more challenging when the test set contains classes that are not part of the train set, ie, a task incremental generalized zero-shot learning problem. Our approach can be used in both the zero-shot and non zero-shot task incremental learning settings. Our proposed method uses weight rectifications and affine transformations in order to adapt the model to different tasks that arrive sequentially. Specifically, we adapt the network weights to work for new tasks by" rectifying" the weights learned from the previous task. We learn these weight rectifications using very few parameters. We additionally learn affine transformations on the outputs generated by the network in order to better adapt them for the new task. We perform experiments on several datasets in both zero-shot and non zero-shot task incremental learning settings and empirically show that our approach achieves state-of-the-art results. Specifically, our approach outperforms the state-of-the-art non zero-shot task incremental learning method by over 5% on the CIFAR-100 dataset. Our approach also significantly outperforms the state-of-the-art task incremental generalized zero-shot learning method by absolute margins of 6.91% and 6.33% for the AWA1 and CUB datasets, respectively. We validate our approach using various ablation studies.'}
@article{mazumder2021few,
  title={Few-shot lifelong learning},
  author={Mazumder, Pratik and Singh, Pravendra and Rai, Piyush},
  journal={AAAI Conference on Artificial Intelligence},
  year={2021}
}
@inproceedings{singh2020calibrating,
  title={Calibrating cnns for lifelong learning},
  author={Singh, Pravendra and Verma, Vinay Kumar and Mazumder, Pratik and Carin, Lawrence and Rai, Piyush},
  booktitle={Advances in Neural Information Processing Systems},
  pages={13702--13713},
  year={2020}
}
@inproceedings{singh2021rectification,
  title={Rectification-based knowledge retention for continual learning},
  author={Singh, Pravendra and Mazumder, Pratik and Rai, Piyush and Namboodiri, Vinay P},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={13790--13799},
  year={2021}   
}


Pratik Mazumder	
HomePublicationsStudentsExperienceCoursesEducationContact
Publications
JOURNAL PUBLICATIONS

Mitigate Forgetting in Few-Shot Class-Incremental Learning Using Different Image Views, Pratik Mazumder, Pravendra Singh, Neural Networks (NEUNET) In Press, 2023.

Leveraging Joint Incremental Learning Objective with Data Ensemble for Class Incremental Learning, Pratik Mazumder, Mohammed Asad Karim, Indu Joshi, Pravendra Singh, Neural Networks (NEUNET) In Press, 2023.

Rectification-based Knowledge Retention for Task Incremental Learning, Pratik Mazumder*, Pravendra Singh*, Piyush Rai, Vinay P. Namboodiri, IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI) In Press, 2024. 

Few-Shot Image Classification with Composite Rotation based Self-Supervised Auxiliary Task, Pratik Mazumder*, Pravendra Singh*, Neurocomputing (NEUCOM), 2022.

Protected Attribute Guided Representation Learning for Bias Mitigation in Limited Data, Pratik Mazumder*, Pravendra Singh*, Knowledge-Based Systems (KBS), 2022.

Dual Class Representation Learning for Few-Shot Image Classification, Pratik Mazumder*, Pravendra Singh*, Knowledge-Based Systems (KBS), 2022.

Context Extraction Module for Deep Convolutional Neural Networks, Pratik Mazumder*, Pravendra Singh*, Vinay P. Namboodiri, Pattern Recognition (PR), 2022.

Calibrating Feature Maps for Deep CNNs, Pratik Mazumder*, Pravendra Singh*, Mohammed Asad Karim*, Vinay P. Namboodiri, Neurocomputing (NEUCOM), 2021.

GIFSL - Grafting based Improved Few-Shot Learning, Pratik Mazumder, Pravendra Singh, Vinay P. Namboodiri, Image and Vision Computing (IMAVIS), 2020.

CONFERENCE PUBLICATIONS

Hybrid Sample Synthesis-based Debiasing of Classifier in Limited Data Setting, Piyush Arora*, Pratik Mazumder*,  IEEE/CVF Winter Conference on Applications of Computer Vision (WACV), Waikoloa, Hawaii, USA, 2024.

Attaining Class-level Forgetting in Pretrained Model using Few Samples, Pratik Mazumder*, Pravendra Singh*, Mohammed Asad Karim*, European Conference on Computer Vision (ECCV), Tel Aviv, Israel, 2022.

Fair Visual Recognition in Limited Data Regime using Self-Supervision and Self-Distillation, Pratik Mazumder*, Pravendra Singh*, Vinay P. Namboodiri, IEEE/CVF Winter Conference on Applications of Computer Vision (WACV), Waikoloa, Hawaii, USA, 2022.

Rectification-based Knowledge Retention for Continual Learning, Pratik Mazumder*, Pravendra Singh*, Piyush Rai, Vinay P. Namboodiri, IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), Virtual Conference, 2021.

Few-Shot Lifelong Learning, Pratik Mazumder*, Pravendra Singh*, Piyush Rai, AAAI Conference on Artificial Intelligence (AAAI), Virtual Conference, 2021.

RNNP: A Robust Few-Shot Learning Approach, Pratik Mazumder, Pravendra Singh, Vinay P. Namboodiri, IEEE/CVF Winter Conference on Applications of Computer Vision (WACV), Hawaii, USA (shifted online), 2021.

AVGZSLNet: Audio-Visual Generalized Zero-Shot Learning by Reconstructing Label Features from Multi-Modal Embeddings, Pratik Mazumder, Pravendra Singh, Kranti Kumar Parida, Vinay P. Namboodiri, IEEE/CVF Winter Conference on Applications of Computer Vision (WACV), Hawaii, USA (shifted online), 2021.

Improving Few-Shot Learning using Composite Rotation based Auxiliary Task, Pratik Mazumder, Pravendra Singh, Vinay P. Namboodiri, IEEE/CVF Winter Conference on Applications of Computer Vision (WACV), Hawaii, USA (shifted online), 2021.

Calibrating CNNs for Lifelong Learning, Pravendra Singh*,  Vinay Kumar Verma*, Pratik Mazumder, Lawrence Carin, Piyush Rai, Conference on Neural Information Processing Systems (NeurIPS), Virtual Conference, 2020.

Passive Batch Injection Training Technique: Boosting Network Performance by Injecting Mini-Batches from a different Data Distribution, Pravendra Singh, Pratik Mazumder, Vinay P. Namboodiri, IEEE International Joint Conference on Neural Networks (IJCNN), Glasgow, Scotland, UK, 2020.

CPWC: Contextual Point Wise Convolution for Object Recognition, Pratik Mazumder*, Pravendra Singh*, Vinay P. Namboodiri, IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), Barcelona, Spain, 2020.

Accuracy Booster: Performance Boosting using Feature Map Re-calibration, Pravendra Singh, Pratik Mazumder, Vinay P. Namboodiri, IEEE/CVF Winter Conference on Applications of Computer Vision (WACV), Colorado, USA, 2020.

# Bibliography
@article{mazumder2024mitigate,
  title={Mitigate Forgetting in Few-Shot Class-Incremental Learning Using Different Image Views},
  author={Mazumder, Pratik and Singh, Pravendra},
  journal={Neural Networks},
  year={2024},
  publisher={Elsevier}
}

@article{mazumder2024leveraging,
  title={Leveraging Joint Incremental Learning Objective with Data Ensemble for Class Incremental Learning},
  author={Mazumder, Pratik and Karim, Mohammed Asad and Joshi, Indu and Singh, Pravendra},
  journal={Neural Networks},
  year={2024},
  publisher={Elsevier}
}

@article{mazumder2024rectification,
  title={Rectification-based Knowledge Retention for Task Incremental Learning},
  author={Mazumder, Pratik and Singh, Pravendra and Rai, Piyush and Namboodiri, Vinay P},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
  year={2024},
  publisher={IEEE}
}

@article{mazumder2022few,
  title={Few-Shot Image Classification with Composite Rotation based Self-Supervised Auxiliary Task},
  author={Mazumder, Pratik and Singh, Pravendra},
  journal={Neurocomputing},
  volume={483},
  pages={223--234},
  year={2022},
  publisher={Elsevier}
}

@article{mazumder2022protected,
  title={Protected Attribute Guided Representation Learning for Bias Mitigation in Limited Data},
  author={Mazumder, Pratik and Singh, Pravendra},
  journal={Knowledge-Based Systems},
  volume={238},
  pages={107926},
  year={2022},
  publisher={Elsevier}
}

@article{mazumder2022dual,
  title={Dual Class Representation Learning for Few-Shot Image Classification},
  author={Mazumder, Pratik and Singh, Pravendra},
  journal={Knowledge-Based Systems},
  volume={236},
  pages={107689},
  year={2022},
  publisher={Elsevier}
}

@article{mazumder2022context,
  title={Context Extraction Module for Deep Convolutional Neural Networks},
  author={Mazumder, Pratik and Singh, Pravendra and Namboodiri, Vinay P},
  journal={Pattern Recognition},
  volume={122},
  pages={108285},
  year={2022},
  publisher={Elsevier}
}

@article{mazumder2021calibrating,
  title={Calibrating Feature Maps for Deep CNNs},
  author={Mazumder, Pratik and Singh, Pravendra and Karim, Mohammed Asad and Namboodiri, Vinay P},
  journal={Neurocomputing},
  volume={453},
  pages={247--257},
  year={2021},
  publisher={Elsevier}
}

@article{mazumder2020gifsl,
  title={GIFSL - Grafting based Improved Few-Shot Learning},
  author={Mazumder, Pratik and Singh, Pravendra and Namboodiri, Vinay P},
  journal={Image and Vision Computing},
  volume={96},
  pages={103908},
  year={2020},
  publisher={Elsevier}
}

@inproceedings{mazumder2024hybrid,
  title={Hybrid Sample Synthesis-based Debiasing of Classifier in Limited Data Setting},
  author={Arora, Piyush and Mazumder, Pratik},
  booktitle={IEEE/CVF Winter Conference on Applications of Computer Vision (WACV)},
  year={2024}
}

@inproceedings{mazumder2022attaining,
  title={Attaining Class-level Forgetting in Pretrained Model using Few Samples},
  author={Mazumder, Pratik and Singh, Pravendra and Karim, Mohammed Asad},
  booktitle={European Conference on Computer Vision (ECCV)},
  year={2022}
}

@inproceedings{mazumder2022fair,
  title={Fair Visual Recognition in Limited Data Regime using Self-Supervision and Self-Distillation},
  author={Mazumder, Pratik and Singh, Pravendra and Namboodiri, Vinay P},
  booktitle={IEEE/CVF Winter Conference on Applications of Computer Vision (WACV)},
  year={2022}
}

@inproceedings{mazumder2021rectification,
  title={Rectification-based Knowledge Retention for Continual Learning},
  author={Mazumder, Pratik and Singh, Pravendra and Rai, Piyush and Namboodiri, Vinay P},
  booktitle={IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2021}
}

@inproceedings{mazumder2021few,
  title={Few-Shot Lifelong Learning},
  author={Mazumder, Pratik and Singh, Pravendra and Rai, Piyush},
  booktitle={AAAI Conference on Artificial Intelligence (AAAI)},
  year={2021}
}

@inproceedings{mazumder2021rnnp,
  title={RNNP: A Robust Few-Shot Learning Approach},
  author={Mazumder, Pratik and Singh, Pravendra and Namboodiri, Vinay P},
  booktitle={IEEE/CVF Winter Conference on Applications of Computer Vision (WACV)},
  year={2021}
}
@inproceedings{mazumder2021avgzslnet,
  title={AVGZSLNet: Audio-Visual Generalized Zero-Shot Learning by Reconstructing Label Features from Multi-Modal Embeddings},
  author={Mazumder, Pratik and Singh, Pravendra and Parida, Kranti Kumar and Namboodiri, Vinay P},
  booktitle={IEEE/CVF Winter Conference on Applications of Computer Vision (WACV)},
  year={2021}
}
@inproceedings{mazumder2021improving,
  title={Improving Few-Shot Learning using Composite Rotation based Auxiliary Task},
  author={Mazumder, Pratik and Singh, Pravendra and Namboodiri, Vinay P},
  booktitle={IEEE/CVF Winter Conference on Applications of Computer Vision (WACV)},
  year={2021}
} 

@inproceedings{singh2020calibrating,
  title={Calibrating cnns for lifelong learning},
  author={Singh, Pravendra and Verma, Vinay Kumar and Mazumder, Pratik and Carin, Lawrence and Rai, Piyush},
  booktitle={Advances in Neural Information Processing Systems},
  pages={13702--13713},
  year={2020}
}
@inproceedings{singh2020passive,
  title={Passive Batch Injection Training Technique: Boosting Network Performance by Injecting Mini-Batches from a different Data Distribution},
  author={Singh, Pravendra and Mazumder, Pratik and Namboodiri, Vinay P},
  booktitle={IEEE International Joint Conference on Neural Networks (IJCNN)},
  pages={1--8},
  year={2020}
}
@inproceedings{mazumder2020cpwc,
  title={CPWC: Contextual Point Wise Convolution for Object Recognition},
  author={Mazumder, Pratik and Singh, Pravendra and Namboodiri, Vinay P},
  booktitle={IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={3252--3256},
  year={2020}
}
@inproceedings{singh2020accuracy,
  title={Accuracy Booster: Performance Boosting using Feature Map Re-calibration},
  author={Singh, Pravendra and Mazumder, Pratik and Namboodiri, Vinay P},
  booktitle={IEEE/CVF Winter Conference on Applications of Computer Vision (WACV)},
  pages={1374--1383},
  year={2020}
} 

